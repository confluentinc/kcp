package kafka

import (
	"fmt"
	"log/slog"

	kafkatypes "github.com/aws/aws-sdk-go-v2/service/kafka/types"
	"github.com/confluentinc/kcp/internal/client"
	"github.com/confluentinc/kcp/internal/types"
)

// KafkaService handles all Kafka-related operations for cluster scanning
type KafkaService struct {
	client     client.KafkaAdmin
	authType   types.AuthType
	clusterArn string
}

// KafkaServiceOpts contains options for creating a new KafkaService
type KafkaServiceOpts struct {
	AuthType   types.AuthType
	ClusterArn string
}

// NewKafkaService creates a new KafkaService instance
func NewKafkaService(kafkaAdmin client.KafkaAdmin, opts KafkaServiceOpts) *KafkaService {
	return &KafkaService{
		client:     kafkaAdmin,
		authType:   opts.AuthType,
		clusterArn: opts.ClusterArn,
	}
}

// ScanKafkaResources scans all Kafka-related resources and populates the cluster information
func (ks *KafkaService) ScanKafkaResources(clusterInfo *types.ClusterInformation) error {
	// Get cluster metadata including broker information and ClusterID
	clusterMetadata, err := ks.DescribeKafkaCluster()
	if err != nil {
		return err
	}

	clusterInfo.ClusterID = clusterMetadata.ClusterID

	topics, err := ks.ScanClusterTopics()
	if err != nil {
		return err
	}
	clusterInfo.SetTopics(topics)

	// Serverless clusters do not support Kafka Admin API and instead returns an EOF error - this should be handled gracefully
	if clusterInfo.Cluster.ClusterType == kafkatypes.ClusterTypeProvisioned {
		acls, err := ks.ScanKafkaAcls()
		if err != nil {
			return err
		}
		clusterInfo.Acls = acls
	} else {
		slog.Warn("‚ö†Ô∏è Serverless clusters do not support querying Kafka ACLs, skipping ACLs scan")
	}

	return nil
}

// scanClusterTopics scans for topics in the Kafka cluster
func (ks *KafkaService) ScanClusterTopics() ([]types.TopicDetails, error) {
	slog.Info("üîç scanning for cluster topics", "clusterArn", ks.clusterArn)

	topics, err := ks.client.ListTopicsWithConfigs()
	if err != nil {
		return nil, fmt.Errorf("‚ùå Failed to list topics with configs: %v", err)
	}

	var topicList []types.TopicDetails
	for topicName, topic := range topics {
		configurations := make(map[string]*string)
		for key, valuePtr := range topic.ConfigEntries {
			if valuePtr != nil {
				configurations[key] = valuePtr
			}
		}

		topicList = append(topicList, types.TopicDetails{
			Name:              topicName,
			Partitions:        int(topic.NumPartitions),
			ReplicationFactor: int(topic.ReplicationFactor),
			Configurations:    configurations,
		})
	}

	return topicList, nil
}

// describeKafkaCluster gets cluster metadata and returns the cluster ID along with logging information
func (ks *KafkaService) DescribeKafkaCluster() (*client.ClusterKafkaMetadata, error) {
	slog.Info("üîç describing kafka cluster", "clusterArn", ks.clusterArn)

	clusterMetadata, err := ks.client.GetClusterKafkaMetadata()
	if err != nil {
		return nil, fmt.Errorf("‚ùå Failed to describe kafka cluster: %v", err)
	}
	return clusterMetadata, nil
}

// ScanKafkaAcls scans for Kafka ACLs in the cluster
func (ks *KafkaService) ScanKafkaAcls() ([]types.Acls, error) {
	slog.Info("üîç scanning for kafka acls", "clusterArn", ks.clusterArn)

	acls, err := ks.client.ListAcls()
	if err != nil {
		return nil, fmt.Errorf("‚ùå Failed to list acls: %v", err)
	}

	// Flatten the ACLs for easier processing
	var flattenedAcls []types.Acls
	for _, resourceAcl := range acls {
		for _, acl := range resourceAcl.Acls {
			flattenedAcl := types.Acls{
				ResourceType:        resourceAcl.ResourceType.String(),
				ResourceName:        resourceAcl.ResourceName,
				ResourcePatternType: resourceAcl.ResourcePatternType.String(),
				Principal:           acl.Principal,
				Host:                acl.Host,
				Operation:           acl.Operation.String(),
				PermissionType:      acl.PermissionType.String(),
			}
			flattenedAcls = append(flattenedAcls, flattenedAcl)
		}
	}

	return flattenedAcls, nil
}
